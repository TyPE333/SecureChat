# SecureChat
Secure and Performance Optimized LLM Inference Using Confidential Computing, Multitenant Orchestration, and Ephemeral Execution

SecureChat combines confidential computing, multitenant orchestration, and ephemeral execution to deliver scalable and secure distributed inference.

#### Project Document
[Project Document](https://docs.google.com/document/d/1SiTb16rfHMk3bPADsA9GcitVUdFqDS-PdL3RZqB8ZOE/edit?usp=sharing)

## Features
- Confidential computing for secure inference
- Optimized performance for large-scale workloads
- Multitenant orchestration for efficient resource sharing
- Ephemeral execution to minimize attack surface

## Architecture (made with Mermaid)
<img width="863" height="161" alt="image" src="https://github.com/user-attachments/assets/3a92ae70-f344-472b-b1fa-e6948d92ffd6" />


## Getting Started
Setup instructions will be added soon.  
For now, please refer to the [Project Document](https://docs.google.com/document/d/1SiTb16rfHMk3bPADsA9GcitVUdFqDS-PdL3RZqB8ZOE/edit?usp=sharing).
